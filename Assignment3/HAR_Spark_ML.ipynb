{"cells":[{"cell_type":"code","source":["# All Includes\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\nfrom sklearn import metrics\n\nimport os"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Useful Constants\n\n# Those are separate normalised input features for the neural network\nINPUT_SIGNAL_TYPES = [\n    \"body_acc_x_\",\n    \"body_acc_y_\",\n    \"body_acc_z_\",\n    \"body_gyro_x_\",\n    \"body_gyro_y_\",\n    \"body_gyro_z_\",\n    \"total_acc_x_\",\n    \"total_acc_y_\",\n    \"total_acc_z_\"\n]\n\n# Output classes to learn how to classify\nLABELS = [\n    \"WALKING\", \n    \"WALKING_UPSTAIRS\", \n    \"WALKING_DOWNSTAIRS\", \n    \"SITTING\", \n    \"STANDING\", \n    \"LAYING\"\n]"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["DATASET_PATH = \"/FileStore/tables/\"\nTRAIN = \"train/\"\nTEST = \"test/\"\n\n\n# Load \"X\" (the neural network's training and testing inputs)\n\ndef load_X(X_signals_paths):\n    X_signals = []\n    \n    for signal_type_path in X_signals_paths:\n      #with open(signal_type_path, \"r\") as file:\n        file = open(\"/dbfs/\"+signal_type_path, 'r')\n        # Read dataset from disk, dealing with text files' syntax\n        X_signals.append(\n            [np.array(serie, dtype=np.float32) for serie in [\n                row.replace('  ', ' ').strip().split(' ') for row in file\n            ]]\n        )\n        file.close()\n    \n    return np.transpose(np.array(X_signals), (1, 2, 0))\n\nX_train_signals_paths = [\n    DATASET_PATH + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n]\nX_test_signals_paths = [\n    DATASET_PATH + TEST +  signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n]\n\nX_train = load_X(X_train_signals_paths)\nX_test = load_X(X_test_signals_paths)\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Load \"y\" (the neural network's training and testing outputs)\n\ndef load_y(y_path):\n    file = open(\"/dbfs\"+y_path, 'r')\n    # Read dataset from disk, dealing with text file's syntax\n    y_ = np.array(\n        [elem for elem in [\n            row.replace('  ', ' ').strip().split(' ') for row in file\n        ]], \n        dtype=np.int32\n    )\n    file.close()\n    \n    # Substract 1 to each output class for friendly 0-based indexing \n    return y_ - 1\n\ny_train_path = DATASET_PATH + \"y_train.txt\"\ny_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n\ny_train = load_y(y_train_path)\ny_test = load_y(y_test_path)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["xtrain_df = pd.DataFrame(X_train.reshape(len(X_train),1152))\nytrain_df = pd.DataFrame(y_train.reshape(len(y_train),1))\nxtest_df = pd.DataFrame(X_test.reshape(len(X_test),1152))\nytest_df = pd.DataFrame(y_test.reshape(len(y_test),1))"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["ytrain_df = ytrain_df.rename(columns={0: 'feature'})"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["trainingData = pd.concat([xtrain_df, ytrain_df], axis=1)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["cols = trainingData.columns"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["cols"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\n\nclassifiers = [\n    DecisionTreeClassifier(),\n    KNeighborsClassifier(7), # because there are 6 different labels\n    SVC(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()\n]\n\nnames = []\nscores = []\n\nfor clf in classifiers:\n    clf = clf.fit(xtrain_df, ytrain_df)\n    ypred = clf.predict(xtest_df)\n    \n    names.append(clf.__class__.__name__)\n    scores.append(accuracy_score(ypred, ytest_df))\n\nscore_df = pd.DataFrame({'Model': names, 'Score': scores}).set_index('Model')\nscore_df"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["ax = score_df.plot.bar()\nax.set_xticklabels(score_df.index, rotation=45, fontsize=10)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["svc_model_linear = SVC(kernel = 'linear', C = 1).fit(xtrain_df, ytrain_df)\nsvc_predictions = svc_model_linear.predict(xtest_df)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["# model accuracy for X_test \naccuracy = svc_model_linear.score(xtest_df, ytest_df)\naccuracy"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# creating a confusion matrix\ncm = confusion_matrix(ytest_df, svc_predictions)\ncm"],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"HAR_Spark_ML","notebookId":414091538568248},"nbformat":4,"nbformat_minor":0}
