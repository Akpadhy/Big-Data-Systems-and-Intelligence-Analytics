<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>HAR_Tensorflow_hyperparameter - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/img/favicon.ico"/>
<script>window.settings = {"enableUsageDeliveryConfiguration":false,"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableClusterMetricsUI":true,"allowWhitelistedIframeDomains":false,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableReservoirTableUI":true,"enableClearStateFeature":true,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"sqlAclsDisabledMap":{"spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"enableRStudioUI":false,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableWorkspaceBrowserSorting":true,"enableSentryLogging":true,"enableFindAndReplace":true,"disallowUrlImportExceptFromDocs":false,"defaultStandardClusterModel":{"cluster_name":"","node_type_id":"dev-tier-node","spark_version":"3.5.x-scala2.11","num_workers":0,"aws_attributes":{"first_on_demand":0,"availability":"ON_DEMAND","zone_id":"us-west-2c","spot_bid_price_percent":100},"autotermination_minutes":120,"default_tags":{"Vendor":"Databricks","Creator":"pardeshi.h@husky.neu.edu","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"shouldShowCommandStatus":false,"createTableInNotebookS3Link":{"url":"https://docs.databricks.com/_static/notebooks/data-import/s3.html","displayName":"S3","workspaceFileName":"S3 Example"},"sanitizeHtmlResult":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableTableAclsConfig":false,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"createTableInNotebookDBFSLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/dbfs.html","displayName":"DBFS","workspaceFileName":"DBFS Example"},"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"allowStyleInSanitizedHtml":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-22756288786762d246bac1381e4f44610a4c2c3135c717c5ac3661822a723f1c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-08d9fc1551087e0876236f19640c4a83116b1649f15137427d21c9056656e80e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-86a9b375074f5afad339e70230ec0ec265c4cefbd280844785fab3bcde5869f9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.5.x-rc-scala2.11","displayName":"3.5.3 RC (Scala 2.11)","packageLabel":"spark-image-331afb47d0086c9d7285abe0bbc287f0fa14287d292eb0d5c1c5bd0f6c48d7bb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-rc-scala2.11","displayName":"4.0.1 RC (Scala 2.11)","packageLabel":"spark-image-b2366b9d28bd638c51313ccc197b9bd787b0e1460dcf2d9e3992317fc8940556","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-f91cb0b3822c6641a9d346ef6c149118fb859b5e511ee01c31e958892ba23c7a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-557788bea0eea16bbf7a8ba13ace07e64dd7fc86270bd5cea086097fe886431f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-gpu-scala2.11","displayName":"3.4.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-279f7f7eee248820ef965982e2305993437bbafccb6b1c5af3fbfb167d74e0ad","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-gpu-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.11","displayName":"Latest RC (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-85e2c9dfe6549bc20f064a46febd4690ffd8f731601ca0fe77158964ffd28398","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-scala2.11","displayName":"Latest stable (Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.11","displayName":"3.3.3 RC (Scala 2.11)","packageLabel":"spark-image-66bc9e6eefdfa764dd3247b8db7500e26da141f7bced8fc865ef02103f2d09fb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-rc-scala2.11","displayName":"3.4.3 RC (Scala 2.11)","packageLabel":"spark-image-f46c95d3e3d9482a9be149c45b39fdb69c67a778330b111dfd99068c9af3c12a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-rc-gpu-scala2.11","displayName":"3.3.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-d6dd8056208d79982bea49e3c3e13a4fbe02d3b93272e0eb10c7cb2c4767e8b5","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"next-major-version-scala2.11","displayName":"Next major version (4.0 snapshot, Scala 2.11)","packageLabel":"spark-image-04bb47b0bae8165f760972376ce05083bc6102645f3f3851cd1cdf9cba13d6fe","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"4.0.x-rc-gpu-scala2.11","displayName":"4.0.1 RC (GPU, Scala 2.11)","packageLabel":"spark-image-fce5c000a5c00e02440d95d0f7e7c638ec57cbf35b9aff88852676e987aa3939","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.10","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.10","displayName":"3.3.3 RC (Scala 2.10)","packageLabel":"spark-image-a73250deec305ed26c43c2ac9dca14ddc593e79eb56025f743e72b22bf81631b","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.10","displayName":"Latest RC (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-stable-scala2.10","displayName":"Latest stable (Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-rc-scala2.10","displayName":"3.4.3 RC (Scala 2.10)","packageLabel":"spark-image-2ffa3a577b482759e9987707816c302de0e0262368808c8f7ea631403954afab","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-gpu-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-66d1366768039140a9f5409f3bab414cb7477ebd8d4bbf8b32cb885120f9f705","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-a7bf439e0add77870466abc6a13e93692102d0241593e27af8d697af03ffe557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-241fa8b78ee6343242b1756b18076270894385ff40a81172a6fb5eadf66155d3","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-gpu-scala2.11","displayName":"3.5.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-035a4d9ac059a77de6e5f6c0d1d7c759a5916cc8cef4bf68ef00fd3c77e2f479","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-7efac6b9a8f2da59cb4f6d0caac46cfcb3f1ebf64c8073498c42d0360f846714","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-46cc39a9afa43fbd7bfa9f4f5ed8d23f658cd0b0d74208627243222ae0d22f8d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"next-major-version-gpu-scala2.11","displayName":"Next major version (4.0 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-41e21a0db3b77bc857f10358917ccbf5fbd85290e8429c2176a5fc7a29ce4f18","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-gpu-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-85e2c9dfe6549bc20f064a46febd4690ffd8f731601ca0fe77158964ffd28398","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-5537926238bc55cb6cd76ee0f0789511349abead3781c4780721a845f34b5d4e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-a7bf439e0add77870466abc6a13e93692102d0241593e27af8d697af03ffe557","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-scala2.10","displayName":"3.5.3 RC (Scala 2.10)","packageLabel":"spark-image-675bf08538f9f4757bad5418e5aefb2e8a07b3866f9abc69112f0bf5b0d82c6e","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.4.x-scala2.10","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-867d7300605c0c54b2b1394d1bba7b88b28ed5841b3575253cded34db6ce6454","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableTableAclsByTier":false,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"createTableInNotebookImportedFileLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/imported-file.html","displayName":"Imported File","workspaceFileName":"Imported File Example"},"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","tableAclsDisabledMap":{"spark.databricks.acl.dfAclsEnabled":"false"},"driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"r4.xlarge":1,"m4.4xlarge":3,"Standard_DS5_v2":3,"Standard_D2s_v3":0.5,"Standard_DS4_v2_Promo":1.5,"Standard_DS14":4,"Standard_DS11_v2_Promo":0.5,"r4.16xlarge":16,"Standard_DS11":0.5,"Standard_D2_v3":0.5,"Standard_DS14_v2_Promo":4,"Standard_D64s_v3":12,"p2.8xlarge":16,"m4.10xlarge":8,"Standard_D8s_v3":1.5,"Standard_E32s_v3":8,"Standard_DS3":0.75,"Standard_DS2_v2":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"Standard_L8s":2,"Standard_DS13_v2_Promo":2,"Standard_E4s_v3":1,"Standard_D3_v2":0.75,"Standard_DS15_v2":5,"Standard_D16s_v3":3,"Standard_D5_v2":3,"Standard_E8s_v3":2,"Standard_DS2_v2_Promo":0.5,"c3.8xlarge":4,"Standard_D4_v3":0.75,"Standard_E2s_v3":0.5,"Standard_D32_v3":6,"Standard_DS3_v2":0.75,"r3.4xlarge":4,"Standard_DS4":1.5,"i2.4xlarge":6,"Standard_DS3_v2_Promo":0.75,"m4.xlarge":0.75,"r4.8xlarge":8,"Standard_H16":4,"Standard_DS14_v2":4,"r4.large":0.5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"i3.large":0.75,"memory-optimized":1,"m4.large":0.4,"Standard_D16_v3":3,"Standard_F4s":0.5,"p2.16xlarge":24,"i3.8xlarge":8,"Standard_D32s_v3":6,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_L32s":8,"Standard_D4s_v3":0.75,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS12_v2_Promo":1,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1,"Standard_F16s":2,"c4.2xlarge":1,"Standard_L16s":4,"i2.xlarge":1.5,"Standard_DS2":0.5,"compute-optimized":1,"c4.4xlarge":2,"Standard_DS5_v2_Promo":3,"Standard_D64_v3":12,"Standard_D2_v2":0.5,"Standard_D8_v3":1.5,"i3.2xlarge":2,"Standard_E16s_v3":4,"Standard_F8s":1,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"Standard_DS4_v2":1.5,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"tableFilesBaseFolder":"/tables","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableClusterAppsUIOnServerless":false,"enableEBSVolumesUI":false,"homePageWelcomeMessage":"Welcome to ","metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.67.1037","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":true,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"broadenedEditPermission":false,"disableS3TableImport":false,"enableArrayParamsEdit":true,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"createTableConnectorOptionLinks":[{"url":"https://docs.databricks.com/_static/notebooks/redshift.html","displayName":"Amazon Redshift","workspaceFileName":"Amazon Redshift Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-kinesis.html","displayName":"Amazon Kinesis","workspaceFileName":"Amazon Kinesis Example"},{"url":"https://docs.databricks.com/_static/notebooks/data-import/jdbc.html","displayName":"JDBC","workspaceFileName":"JDBC Example"},{"url":"https://docs.databricks.com/_static/notebooks/cassandra.html","displayName":"Cassandra","workspaceFileName":"Cassandra Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html","displayName":"Kafka","workspaceFileName":"Kafka Example"},{"url":"https://docs.databricks.com/_static/notebooks/redis.html","displayName":"Redis","workspaceFileName":"Redis Example"},{"url":"https://docs.databricks.com/_static/notebooks/elasticsearch.html","displayName":"Elasticsearch","workspaceFileName":"Elasticsearch Example"}],"enableStaticNotebooks":true,"enableNewLineChart":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterEdit":true,"enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"commandStatusDebounceMaxWait":5000,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableExperimentalCharts":false,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"serverlessRunPythonAsLowPrivilegeUser":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"enableJobListPermissionFilter":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},"enableNewLineChartParams":false,"deprecatedEnableStructuredDataAcls":false,"enableCustomSpotPricing":false,"enableRStudioFreeUI":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":true,"disableExportNotebook":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","commandStatusDebounceInterval":1000,"showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"defaultTagKeys":{"CLUSTER_NAME":"ClusterName","VENDOR":"Vendor","CLUSTER_TYPE":"ResourceClass","CREATOR":"Creator","CLUSTER_ID":"ClusterId"},"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","customSparkVersionPrefix":"custom:","disallowAddingAdmins":true,"enableSparkConfUI":true,"enableClusterEventsUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","defaultServerlessClusterModel":{"cluster_name":"","node_type_id":"i3.2xlarge","spark_version":"latest-stable-scala2.11","num_workers":null,"enable_jdbc_auto_start":true,"custom_tags":{"ResourceClass":"Serverless"},"autoscale":{"min_workers":2,"max_workers":20},"spark_conf":{"spark.databricks.cluster.profile":"serverless","spark.databricks.repl.allowedLanguages":"sql,python,r","spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"aws_attributes":{"ebs_volume_count":null,"availability":"ON_DEMAND","first_on_demand":1,"ebs_volume_type":null,"spot_bid_price_percent":100,"zone_id":"us-west-2c","ebs_volume_size":null},"autotermination_minutes":0,"enable_elastic_disk":false,"default_tags":{"Vendor":"Databricks","Creator":"pardeshi.h@husky.neu.edu","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableClusterAppsUIOnNormalClusters":false,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"homePageLogo":"login/databricks_logoTM_rgb_TM.svg","enableWebappSharding":true,"enableNotebookParamsEdit":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableRServerless":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"","clusterTagReservedPrefixes":[],"tableAclsEnabledMap":{"spark.databricks.acl.dfAclsEnabled":"true"},"showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","databricksDocsNotebookPathPrefix":"^https://docs\\.databricks\\.com/_static/notebooks/.+$","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":true,"allowFeedbackForumAccess":true,"enablePythonVersionUI":true,"enableImportFromUrl":true,"allowDisplayHtmlByUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"loginLogo":"/login/databricks_logoTM_rgb_TM.svg","useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"useIframeForHtmlResult":false,"enableClusterTagsUIByTier":false,"enableUserPromptForPendingRpc":false,"enableNotebookHistoryUI":true,"addWhitespaceAfterLastNotebookCell":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"maxImportFileVersion":5,"enableEBSVolumesUIByTier":false,"enableTableAclService":true,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"showResultsFromExternalSearchEngine":true,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":3300760951503223,"name":"HAR_Tensorflow_hyperparameter","language":"python","commands":[{"version":"CommandV1","origId":3300760951503224,"guid":"d18b59c1-c9db-4375-813e-9804a3e7187d","subtype":"command","commandType":"auto","position":1.0,"command":"# All Includes\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\nfrom sklearn import metrics\n\nimport os","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">ImportError</span>: No module named &apos;tensorflow&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2638989866570141&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansigreen\">import</span> matplotlib<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansigreen\">import</span> matplotlib<span class=\"ansiyellow\">.</span>pyplot <span class=\"ansigreen\">as</span> plt<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 6</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">import</span> tensorflow <span class=\"ansigreen\">as</span> tf  <span class=\"ansired\"># Version 1.0.0 (some previous versions are used in past commits)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      7</span> <span class=\"ansigreen\">from</span> sklearn <span class=\"ansigreen\">import</span> metrics<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      8</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ImportError</span>: No module named &apos;tensorflow&apos;</div>","workflows":[],"startTime":1521845330774,"submitTime":1521845330764,"finishTime":1521845331161,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3a4a7cb4-cfbf-4d33-b1ee-115d07cfa563"},{"version":"CommandV1","origId":3300760951503246,"guid":"120d3eff-b597-4daf-b970-ebad4a9d9e82","subtype":"command","commandType":"auto","position":1.5,"command":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport sys\n\nimport tensorflow.python.platform\n\nfrom six.moves import urllib\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\nimport itertools","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845336960,"submitTime":1521845336947,"finishTime":1521845337006,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8250cd0d-8e93-478b-a39f-522ab3ec1dce"},{"version":"CommandV1","origId":3300760951503247,"guid":"535b061a-f9db-4b94-9284-1d0b1298a4ba","subtype":"command","commandType":"auto","position":1.75,"command":"NUM_LABELS = 6\nVALIDATION_SIZE = 500  # Size of the validation set.\nSEED = 66478  # Set to None for random seed.\nBATCH_SIZE = 64\nNUM_EPOCHS = 2","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845338271,"submitTime":1521845338260,"finishTime":1521845338348,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d98bd8d0-6215-43ca-a43f-898c8fe4ad0a"},{"version":"CommandV1","origId":3300760951503225,"guid":"d34c58a5-8c6e-4b1a-b1c4-ca33fa5127b3","subtype":"command","commandType":"auto","position":2.0,"command":"# Useful Constants\n\n# Those are separate normalised input features for the neural network\nINPUT_SIGNAL_TYPES = [\n    \"body_acc_x_\",\n    \"body_acc_y_\",\n    \"body_acc_z_\",\n    \"body_gyro_x_\",\n    \"body_gyro_y_\",\n    \"body_gyro_z_\",\n    \"total_acc_x_\",\n    \"total_acc_y_\",\n    \"total_acc_z_\"\n]\n\n# Output classes to learn how to classify\nLABELS = [\n    \"WALKING\", \n    \"WALKING_UPSTAIRS\", \n    \"WALKING_DOWNSTAIRS\", \n    \"SITTING\", \n    \"STANDING\", \n    \"LAYING\"\n]","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845339443,"submitTime":1521845339430,"finishTime":1521845339519,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b7ec4711-e340-4ad8-801d-e3554f6f76a2"},{"version":"CommandV1","origId":3300760951503226,"guid":"ebb94bc8-307e-497f-aab6-5f06631998de","subtype":"command","commandType":"auto","position":3.0,"command":"DATASET_PATH = \"/FileStore/tables/\"\nTRAIN = \"train/\"\nTEST = \"test/\"\n\n\n# Load \"X\" (the neural network's training and testing inputs)\n\ndef load_X(X_signals_paths):\n    X_signals = []\n    \n    for signal_type_path in X_signals_paths:\n      #with open(signal_type_path, \"r\") as file:\n        file = open(\"/dbfs/\"+signal_type_path, 'r')\n        # Read dataset from disk, dealing with text files' syntax\n        X_signals.append(\n            [np.array(serie, dtype=np.float32) for serie in [\n                row.replace('  ', ' ').strip().split(' ') for row in file\n            ]]\n        )\n        file.close()\n    \n    return np.transpose(np.array(X_signals), (1, 2, 0))\n\nX_train_signals_paths = [\n    DATASET_PATH + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n]\nX_test_signals_paths = [\n    DATASET_PATH + TEST +  signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n]\n\nX_train = load_X(X_train_signals_paths)\nX_test = load_X(X_test_signals_paths)\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: global name &apos;np&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3300760951503226&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     29</span> ]\n<span class=\"ansigreen\">     30</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 31</span><span class=\"ansiyellow\"> </span>X_train <span class=\"ansiyellow\">=</span> load_X<span class=\"ansiyellow\">(</span>X_train_signals_paths<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     32</span> X_test <span class=\"ansiyellow\">=</span> load_X<span class=\"ansiyellow\">(</span>X_test_signals_paths<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-3300760951503226&gt;</span> in <span class=\"ansicyan\">load_X</span><span class=\"ansiblue\">(X_signals_paths)</span>\n<span class=\"ansigreen\">     15</span>         X_signals.append(\n<span class=\"ansigreen\">     16</span>             [np.array(serie, dtype=np.float32) for serie in [\n<span class=\"ansigreen\">---&gt; 17</span><span class=\"ansiyellow\">                 </span>row<span class=\"ansiyellow\">.</span>replace<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;  &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&apos; &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>strip<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos; &apos;</span><span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">for</span> row <span class=\"ansigreen\">in</span> file<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     18</span>             ]]\n<span class=\"ansigreen\">     19</span>         )\n\n<span class=\"ansired\">NameError</span>: global name &apos;np&apos; is not defined</div>","workflows":[],"startTime":1521845340674,"submitTime":1521845340661,"finishTime":1521845352759,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"63c34c37-7df0-4683-aa38-8902ea8f0027"},{"version":"CommandV1","origId":3300760951503227,"guid":"c0ee3aef-7a1d-444f-b3ac-d221d0afc212","subtype":"command","commandType":"auto","position":4.0,"command":"# Load \"y\" (the neural network's training and testing outputs)\n\ndef load_y(y_path):\n    file = open(\"/dbfs\"+y_path, 'r')\n    # Read dataset from disk, dealing with text file's syntax\n    y_ = np.array(\n        [elem for elem in [\n            row.replace('  ', ' ').strip().split(' ') for row in file\n        ]], \n        dtype=np.int32\n    )\n    file.close()\n    \n    # Substract 1 to each output class for friendly 0-based indexing \n    return y_ - 1\n\ny_train_path = DATASET_PATH + \"y_train.txt\"\ny_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n\ny_train = load_y(y_train_path)\ny_test = load_y(y_test_path)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">FileNotFoundError</span>: [Errno 2] No such file or directory: &apos;/dbfs/FileStore/tables/train/y_train.txt&apos;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">FileNotFoundError</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2638989866570146&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     18</span> y_test_path <span class=\"ansiyellow\">=</span> DATASET_PATH <span class=\"ansiyellow\">+</span> TEST <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&quot;y_test.txt&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     19</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 20</span><span class=\"ansiyellow\"> </span>y_train <span class=\"ansiyellow\">=</span> load_y<span class=\"ansiyellow\">(</span>y_train_path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     21</span> y_test <span class=\"ansiyellow\">=</span> load_y<span class=\"ansiyellow\">(</span>y_test_path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">&lt;command-2638989866570146&gt;</span> in <span class=\"ansicyan\">load_y</span><span class=\"ansiblue\">(y_path)</span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansigreen\">def</span> load_y<span class=\"ansiyellow\">(</span>y_path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 4</span><span class=\"ansiyellow\">     </span>file <span class=\"ansiyellow\">=</span> open<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;/dbfs&quot;</span><span class=\"ansiyellow\">+</span>y_path<span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&apos;r&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span>     <span class=\"ansired\"># Read dataset from disk, dealing with text file&apos;s syntax</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span>     y_ = np.array(\n\n<span class=\"ansired\">FileNotFoundError</span>: [Errno 2] No such file or directory: &apos;/dbfs/FileStore/tables/train/y_train.txt&apos;</div>","workflows":[],"startTime":1521845554675,"submitTime":1521845554660,"finishTime":1521845555200,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c1eabd87-fd28-4dff-9457-740b97873d39"},{"version":"CommandV1","origId":3300760951503228,"guid":"c5a32a0c-4be1-4a80-a722-907d1e924914","subtype":"command","commandType":"auto","position":5.0,"command":"# Input Data \n\ntraining_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\ntest_data_count = len(X_test)  # 2947 testing series\nn_steps = len(X_train[0])  # 128 timesteps per series\nn_input = len(X_train[0][0])  # 9 input parameters per timestep","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845565501,"submitTime":1521845565490,"finishTime":1521845565551,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6a33de63-fd28-402d-8f18-e49f7d0f3ab4"},{"version":"CommandV1","origId":3300760951503229,"guid":"b35c7679-bb37-4c53-90a5-1ceb49f58438","subtype":"command","commandType":"auto","position":6.0,"command":"# LSTM Neural Network's internal structure\n\nn_hidden = 32 # Hidden layer num of features\nn_classes = 6 # Total classes (should go up, or should go down)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845659780,"submitTime":1521845659769,"finishTime":1521845659854,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"94d45c94-6f0a-42d8-9eb3-5b7970fcb550"},{"version":"CommandV1","origId":3300760951503230,"guid":"d32868dc-5d74-4cac-a53b-8c633436fb03","subtype":"command","commandType":"auto","position":7.0,"command":"# Training \n\nlearning_rate = 0.0025\nlambda_loss_amount = 0.0015\ntraining_iters = training_data_count * 300  # Loop 300 times on the dataset\nbatch_size = 1500\ndisplay_iter = 30000  # To show test set accuracy during training","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845787873,"submitTime":1521845787862,"finishTime":1521845787899,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5d4376fa-2061-4a01-9987-e237101278d3"},{"version":"CommandV1","origId":3300760951503231,"guid":"5f3039fa-d84e-4916-bebd-238777106d5a","subtype":"command","commandType":"auto","position":8.0,"command":"# Some debugging info\n\nprint(\"Some useful info to get an insight on dataset's shape and normalisation:\")\nprint(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\nprint(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\nprint(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Some useful info to get an insight on dataset&apos;s shape and normalisation:\n(X shape, y shape, every X&apos;s mean, every X&apos;s standard deviation)\n(2947, 128, 9) (2947, 1) 0.09913992 0.39567086\nThe dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845795524,"submitTime":1521845795514,"finishTime":1521845795651,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0fc901df-afa4-47a3-816b-d328fc9b6030"},{"version":"CommandV1","origId":3300760951503232,"guid":"c015345c-059e-43b8-9fd9-c18b33a3e430","subtype":"command","commandType":"auto","position":9.0,"command":"def LSTM_RNN(_X, _weights, _biases):\n    # Function returns a tensorflow LSTM (RNN) artificial neural network from given parameters. \n    # Moreover, two LSTM cells are stacked which adds deepness to the neural network. \n    # Note, some code of this notebook is inspired from an slightly different \n    # RNN architecture used on another dataset, some of the credits goes to \n    # \"aymericdamien\" under the MIT license.\n\n    # (NOTE: This step could be greatly optimised by shaping the dataset once\n    # input shape: (batch_size, n_steps, n_input)\n    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n    # Reshape to prepare input to hidden activation\n    _X = tf.reshape(_X, [-1, n_input]) \n    # new shape: (n_steps*batch_size, n_input)\n    \n    # Linear activation\n    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n    _X = tf.split(_X, n_steps, 0) \n    # new shape: n_steps * (batch_size, n_hidden)\n\n    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n    # Get LSTM cell output\n    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n\n    # Get last time step's output feature for a \"many to one\" style classifier, \n    # as in the image describing RNNs at the top of this page\n    lstm_last_output = outputs[-1]\n    \n    # Linear activation\n    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845796636,"submitTime":1521845796625,"finishTime":1521845796712,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"992e5e5a-a809-4490-a98a-01abff1d680a"},{"version":"CommandV1","origId":3300760951503233,"guid":"dc7f179b-03da-4cfb-b193-40cea23d51ec","subtype":"command","commandType":"auto","position":10.0,"command":"def extract_batch_size(_train, step, batch_size):\n    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n    \n    shape = list(_train.shape)\n    shape[0] = batch_size\n    batch_s = np.empty(shape)\n\n    for i in range(batch_size):\n        # Loop index\n        index = ((step-1)*batch_size + i) % len(_train)\n        batch_s[i] = _train[index] \n\n    return batch_s","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845797764,"submitTime":1521845797752,"finishTime":1521845797837,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8afd942b-7714-4863-8925-5cb6471e1100"},{"version":"CommandV1","origId":3300760951503234,"guid":"10c79178-5a54-480d-b11c-888bf5f426cd","subtype":"command","commandType":"auto","position":11.0,"command":"def one_hot(y_):\n    # Function to encode output labels from number indexes \n    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n    \n    y_ = y_.reshape(len(y_))\n    n_values = int(np.max(y_)) + 1\n    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845799520,"submitTime":1521845799509,"finishTime":1521845799549,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f6b8f9a3-07f1-4b51-8921-667e213c2e26"},{"version":"CommandV1","origId":3300760951503235,"guid":"7fdc546f-abba-4c33-a844-025a471fa9a9","subtype":"command","commandType":"auto","position":12.0,"command":"# Graph input/output\nx = tf.placeholder(tf.float32, [None, n_steps, n_input])\ny = tf.placeholder(tf.float32, [None, n_classes])\n\n# Graph weights\nweights = {\n    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n}\nbiases = {\n    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n    'out': tf.Variable(tf.random_normal([n_classes]))\n}","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521845804152,"submitTime":1521845804141,"finishTime":1521845804278,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9ab6ad38-ddd4-4976-b8d9-e022fcc4fd6d"},{"version":"CommandV1","origId":3300760951503236,"guid":"feaeac5a-4f3e-4f99-bac0-f66ea6795f9b","subtype":"command","commandType":"auto","position":13.0,"command":"pred = LSTM_RNN(x, weights, biases)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521846539490,"submitTime":1521846539481,"finishTime":1521846543320,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2f256569-cd5f-415f-8b81-c6ab8c94e2d9"},{"version":"CommandV1","origId":3300760951503237,"guid":"490571c2-7c6e-4790-987a-aba4714ca7d1","subtype":"command","commandType":"auto","position":13.5,"command":"# Loss, optimizer and evaluation\nl2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n# L2 loss prevents this overkill neural network to overfit the data\n\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n\ncorrect_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">WARNING:tensorflow:From &lt;command-3300760951503237&gt;:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee tf.nn.softmax_cross_entropy_with_logits_v2.\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521846549481,"submitTime":1521846549470,"finishTime":1521846568280,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"70d04590-dd27-427e-a12b-c5f8a3e5eea5"},{"version":"CommandV1","origId":3300760951503248,"guid":"733ceee0-7b95-4dd5-88ae-a397d57d64e4","subtype":"command","commandType":"auto","position":13.75,"command":"base_learning_rates = [0.00001,0.025,0.0025,0.00001]\nbase_batch_size = [1500, 1000, 2000]\nall_experiments = list(itertools.product(base_learning_rates, base_batch_size))\nprint(len(all_experiments))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">12\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;fc1_sizes&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3300760951503248&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> base_learning_rates <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0.00001</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">0.025</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">0.0025</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">0.00001</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> base_batch_size <span class=\"ansiyellow\">=</span> <span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1500</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1000</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">2000</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>all_experiments <span class=\"ansiyellow\">=</span> list<span class=\"ansiyellow\">(</span>itertools<span class=\"ansiyellow\">.</span>product<span class=\"ansiyellow\">(</span>base_learning_rates<span class=\"ansiyellow\">,</span> fc1_sizes<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>len<span class=\"ansiyellow\">(</span>all_experiments<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;fc1_sizes&apos; is not defined</div>","workflows":[],"startTime":1521851815988,"submitTime":1521851815978,"finishTime":1521851816030,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"acea4bae-cb7e-4345-9708-fd725057aefe"},{"version":"CommandV1","origId":3300760951503249,"guid":"f50e506c-0c20-44c7-976e-cbed2e4f0a7c","subtype":"command","commandType":"auto","position":13.875,"command":"all_exps_rdd = sc.parallelize(all_experiments, numSlices=len(all_experiments))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax","error":"<div class=\"ansiout\"><span class=\"ansicyan\">  File </span><span class=\"ansigreen\">&quot;&lt;command-3300760951503249&gt;&quot;</span><span class=\"ansicyan\">, line </span><span class=\"ansigreen\">1</span>\n<span class=\"ansiyellow\">    all_exps_rdd = sc.parallelize(all_experiments, numSlices=len(all_experiments)) r</span>\n<span class=\"ansigrey\">                                                                                   ^</span>\n<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax\n</div>","workflows":[],"startTime":1521851819343,"submitTime":1521851819333,"finishTime":1521851819417,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"34d3d008-5320-4798-bd59-4e3f09db2136"},{"version":"CommandV1","origId":3300760951503250,"guid":"cfb56e7d-ca05-47f4-bded-4387bbe33b51","subtype":"command","commandType":"auto","position":13.9375,"command":"def run_model(learning_rates,batch_sizes):\n  test_losses = []\n  test_accuracies = []\n  train_losses = []\n  train_accuracies = []\n  \n  res = {}\n  res['base_learning_rate'] = base_learning_rate\n  res['minibatch_loss'] = 100.0\n  res['test_error'] = 100.0\n  res['validation_error'] = 100.0\n  \n    # Launch the graph\n  sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n  init = tf.global_variables_initializer()\n  sess.run(init)\n\n  # Perform Training steps with \"batch_size\" amount of example data at each loop\n  step = 1\n  while step * batch_size <= training_iters:\n      batch_xs =         extract_batch_size(X_train, step, batch_sizes)\n      batch_ys = one_hot(extract_batch_size(y_train, step, batch_sizes))\n\n      # Fit training using batch data\n      _, loss, acc = sess.run(\n          [optimizer, cost, accuracy],\n          feed_dict={\n              x: batch_xs, \n              y: batch_ys\n          }\n      )\n      train_losses.append(loss)\n      train_accuracies.append(acc)\n\n      # Evaluate network only at some steps for faster training: \n      if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n\n          # To not spam console, show training accuracy/loss in this \"if\"\n          print(\"Training iter #\" + str(step*batch_size) + \\\n                \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n                \", Accuracy = {}\".format(acc))\n\n          # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n          loss, acc = sess.run(\n              [cost, accuracy], \n              feed_dict={\n                  x: X_test,\n                  y: one_hot(y_test)\n              }\n          )\n          test_losses.append(loss)\n          test_accuracies.append(acc)\n          print(\"PERFORMANCE ON TEST SET: \" + \\\n                \"Batch Loss = {}\".format(loss) + \\\n                \", Accuracy = {}\".format(acc))\n\n      step += 1\n  res['test_error'] = loss\n  res['test_acc'] = acc\n  print(\"Optimization Finished!\")\n  return res\n  ","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521852022258,"submitTime":1521852022248,"finishTime":1521852022339,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"18084bff-3ab9-4bd8-9037-2327338f19b8"},{"version":"CommandV1","origId":3300760951503238,"guid":"2e800dd1-8634-4892-9d31-490c874af225","subtype":"command","commandType":"auto","position":14.0,"command":"num_nodes = 4\nn = max(2, int(len(all_experiments) // num_nodes))\ngrouped_experiments = [all_experiments[i:i+n] for i in range(0, len(all_experiments), n)]\nall_exps_rdd = sc.parallelize(grouped_experiments, numSlices=len(grouped_experiments))\nresults = all_exps_rdd.flatMap(lambda z: [run_model(*y) for y in z]).collect()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Training iter #1500:   Batch Loss = 2.920060, Accuracy = 0.1979999989271164\nPERFORMANCE ON TEST SET: Batch Loss = 2.38847017288208, Accuracy = 0.1866304725408554\nTraining iter #30000:   Batch Loss = 1.287550, Accuracy = 0.7006666660308838\nPERFORMANCE ON TEST SET: Batch Loss = 1.4170958995819092, Accuracy = 0.6620292067527771\nTraining iter #60000:   Batch Loss = 1.019766, Accuracy = 0.8013333082199097\nPERFORMANCE ON TEST SET: Batch Loss = 1.3756566047668457, Accuracy = 0.708856463432312\nTraining iter #90000:   Batch Loss = 0.952952, Accuracy = 0.8640000224113464\nPERFORMANCE ON TEST SET: Batch Loss = 1.1410000324249268, Accuracy = 0.7994570732116699\nTraining iter #120000:   Batch Loss = 0.813943, Accuracy = 0.8886666893959045\nPERFORMANCE ON TEST SET: Batch Loss = 1.0606718063354492, Accuracy = 0.838819146156311\nTraining iter #150000:   Batch Loss = 0.689059, Accuracy = 0.9393333196640015\nPERFORMANCE ON TEST SET: Batch Loss = 1.0181503295898438, Accuracy = 0.8649473786354065\nTraining iter #180000:   Batch Loss = 0.924733, Accuracy = 0.7866666913032532\nPERFORMANCE ON TEST SET: Batch Loss = 1.0624687671661377, Accuracy = 0.8021717071533203\nTraining iter #210000:   Batch Loss = 0.748922, Accuracy = 0.9126666784286499\nPERFORMANCE ON TEST SET: Batch Loss = 0.9873255491256714, Accuracy = 0.8591788411140442\nTraining iter #240000:   Batch Loss = 0.598940, Accuracy = 0.9733333587646484\nPERFORMANCE ON TEST SET: Batch Loss = 0.889348566532135, Accuracy = 0.88802170753479\nTraining iter #270000:   Batch Loss = 0.581156, Accuracy = 0.981333315372467\nPERFORMANCE ON TEST SET: Batch Loss = 0.8918578624725342, Accuracy = 0.8920936584472656\nTraining iter #300000:   Batch Loss = 0.551621, Accuracy = 0.984666645526886\nPERFORMANCE ON TEST SET: Batch Loss = 0.8514251708984375, Accuracy = 0.8985409140586853\nTraining iter #330000:   Batch Loss = 0.582650, Accuracy = 0.9773333072662354\nPERFORMANCE ON TEST SET: Batch Loss = 0.8382830619812012, Accuracy = 0.8992195725440979\nTraining iter #360000:   Batch Loss = 0.591944, Accuracy = 0.9506666660308838\nPERFORMANCE ON TEST SET: Batch Loss = 0.8250954151153564, Accuracy = 0.9032914638519287\nTraining iter #390000:   Batch Loss = 0.595087, Accuracy = 0.9393333196640015\nPERFORMANCE ON TEST SET: Batch Loss = 0.8295780420303345, Accuracy = 0.8998982310295105\nTraining iter #420000:   Batch Loss = 0.554281, Accuracy = 0.9520000219345093\nPERFORMANCE ON TEST SET: Batch Loss = 0.83122318983078, Accuracy = 0.8954869508743286\nTraining iter #450000:   Batch Loss = 0.538676, Accuracy = 0.9526666402816772\nPERFORMANCE ON TEST SET: Batch Loss = 0.8290797472000122, Accuracy = 0.8978622555732727\nTraining iter #480000:   Batch Loss = 0.687202, Accuracy = 0.8759999871253967\nPERFORMANCE ON TEST SET: Batch Loss = 0.9352813959121704, Accuracy = 0.866644024848938\nTraining iter #510000:   Batch Loss = 0.514714, Accuracy = 0.9739999771118164\nPERFORMANCE ON TEST SET: Batch Loss = 0.7618369460105896, Accuracy = 0.8958262801170349\nTraining iter #540000:   Batch Loss = 0.553776, Accuracy = 0.9340000152587891\nPERFORMANCE ON TEST SET: Batch Loss = 0.7894425392150879, Accuracy = 0.8954869508743286\nTraining iter #570000:   Batch Loss = 0.539351, Accuracy = 0.9319999814033508\nPERFORMANCE ON TEST SET: Batch Loss = 0.7872157096862793, Accuracy = 0.9039701223373413\nTraining iter #600000:   Batch Loss = 0.525214, Accuracy = 0.9193333387374878\nPERFORMANCE ON TEST SET: Batch Loss = 0.7584981918334961, Accuracy = 0.8968442678451538\nTraining iter #630000:   Batch Loss = 0.442265, Accuracy = 0.9753333330154419\nPERFORMANCE ON TEST SET: Batch Loss = 0.8574609756469727, Accuracy = 0.8639293909072876\nTraining iter #660000:   Batch Loss = 0.534698, Accuracy = 0.937333345413208\nPERFORMANCE ON TEST SET: Batch Loss = 0.809249997138977, Accuracy = 0.854428231716156\nTraining iter #690000:   Batch Loss = 0.458467, Accuracy = 0.9726666808128357\nPERFORMANCE ON TEST SET: Batch Loss = 0.7594388127326965, Accuracy = 0.8876823782920837\nTraining iter #720000:   Batch Loss = 0.478888, Accuracy = 0.9539999961853027\nPERFORMANCE ON TEST SET: Batch Loss = 0.7112525105476379, Accuracy = 0.9049881100654602\nTraining iter #750000:   Batch Loss = 0.487435, Accuracy = 0.937333345413208\nPERFORMANCE ON TEST SET: Batch Loss = 0.7684796452522278, Accuracy = 0.8944689631462097\nTraining iter #780000:   Batch Loss = 0.410516, Accuracy = 0.9626666903495789\nPERFORMANCE ON TEST SET: Batch Loss = 0.7637733221054077, Accuracy = 0.8968442678451538\nTraining iter #810000:   Batch Loss = 0.430568, Accuracy = 0.9559999704360962\nPERFORMANCE ON TEST SET: Batch Loss = 0.7656344771385193, Accuracy = 0.8951476216316223\nTraining iter #840000:   Batch Loss = 0.442652, Accuracy = 0.9413333535194397\nPERFORMANCE ON TEST SET: Batch Loss = 0.6678529977798462, Accuracy = 0.8965049386024475\nTraining iter #870000:   Batch Loss = 0.426602, Accuracy = 0.9513333439826965\nPERFORMANCE ON TEST SET: Batch Loss = 0.6520918607711792, Accuracy = 0.9056667685508728\nTraining iter #900000:   Batch Loss = 0.395280, Accuracy = 0.9679999947547913\nPERFORMANCE ON TEST SET: Batch Loss = 0.6643097996711731, Accuracy = 0.9012554883956909\nTraining iter #930000:   Batch Loss = 0.479340, Accuracy = 0.9266666769981384\nPERFORMANCE ON TEST SET: Batch Loss = 0.6713862419128418, Accuracy = 0.9056667685508728\nTraining iter #960000:   Batch Loss = 0.450179, Accuracy = 0.9353333115577698\nPERFORMANCE ON TEST SET: Batch Loss = 0.6802023649215698, Accuracy = 0.9046487808227539\nTraining iter #990000:   Batch Loss = 0.361293, Accuracy = 0.9779999852180481\nPERFORMANCE ON TEST SET: Batch Loss = 0.7285386323928833, Accuracy = 0.8985409140586853\nTraining iter #1020000:   Batch Loss = 0.381055, Accuracy = 0.9633333086967468\nPERFORMANCE ON TEST SET: Batch Loss = 0.6279489994049072, Accuracy = 0.8988802433013916\nTraining iter #1050000:   Batch Loss = 0.335161, Accuracy = 0.987333357334137\nPERFORMANCE ON TEST SET: Batch Loss = 0.6213970184326172, Accuracy = 0.9090600609779358\nTraining iter #1080000:   Batch Loss = 0.372266, Accuracy = 0.9746666550636292\nPERFORMANCE ON TEST SET: Batch Loss = 0.6117783784866333, Accuracy = 0.9046487808227539\nTraining iter #1110000:   Batch Loss = 0.406615, Accuracy = 0.9380000233650208\nPERFORMANCE ON TEST SET: Batch Loss = 0.6424485445022583, Accuracy = 0.9019341468811035\nTraining iter #1140000:   Batch Loss = 0.392550, Accuracy = 0.937333345413208\nPERFORMANCE ON TEST SET: Batch Loss = 0.6436880826950073, Accuracy = 0.9046487808227539\nTraining iter #1170000:   Batch Loss = 0.342049, Accuracy = 0.95333331823349\nPERFORMANCE ON TEST SET: Batch Loss = 0.6899023056030273, Accuracy = 0.8941296339035034\nTraining iter #1200000:   Batch Loss = 0.338461, Accuracy = 0.95333331823349\nPERFORMANCE ON TEST SET: Batch Loss = 0.6676308512687683, Accuracy = 0.9019341468811035\nTraining iter #1230000:   Batch Loss = 0.345406, Accuracy = 0.95333331823349\nPERFORMANCE ON TEST SET: Batch Loss = 0.7190836668014526, Accuracy = 0.882253110408783\nTraining iter #1260000:   Batch Loss = 0.339611, Accuracy = 0.9693333506584167\nPERFORMANCE ON TEST SET: Batch Loss = 0.6520506143569946, Accuracy = 0.9039701223373413\nTraining iter #1290000:   Batch Loss = 0.374375, Accuracy = 0.9353333115577698\nPERFORMANCE ON TEST SET: Batch Loss = 0.6550208330154419, Accuracy = 0.894808292388916\nTraining iter #1320000:   Batch Loss = 0.371849, Accuracy = 0.9353333115577698\nPERFORMANCE ON TEST SET: Batch Loss = 0.6655125617980957, Accuracy = 0.8961656093597412\nTraining iter #1350000:   Batch Loss = 0.363618, Accuracy = 0.949999988079071\nPERFORMANCE ON TEST SET: Batch Loss = 0.6952214241027832, Accuracy = 0.8713946342468262\nTraining iter #1380000:   Batch Loss = 0.288562, Accuracy = 0.9866666793823242\nPERFORMANCE ON TEST SET: Batch Loss = 0.5860252976417542, Accuracy = 0.9026128053665161\nTraining iter #1410000:   Batch Loss = 0.280238, Accuracy = 0.9773333072662354\nPERFORMANCE ON TEST SET: Batch Loss = 0.6116339564323425, Accuracy = 0.9029521346092224\nTraining iter #1440000:   Batch Loss = 0.305065, Accuracy = 0.9833333492279053\nPERFORMANCE ON TEST SET: Batch Loss = 0.6028389930725098, Accuracy = 0.9066847562789917\nTraining iter #1470000:   Batch Loss = 0.324264, Accuracy = 0.9539999961853027\nPERFORMANCE ON TEST SET: Batch Loss = 0.6281411051750183, Accuracy = 0.9032914638519287\nTraining iter #1500000:   Batch Loss = 0.348559, Accuracy = 0.9513333439826965\nPERFORMANCE ON TEST SET: Batch Loss = 0.6359968781471252, Accuracy = 0.882253110408783\nTraining iter #1530000:   Batch Loss = 0.286938, Accuracy = 0.9539999961853027\nPERFORMANCE ON TEST SET: Batch Loss = 0.6295955181121826, Accuracy = 0.9022734761238098\nTraining iter #1560000:   Batch Loss = 0.315941, Accuracy = 0.9513333439826965\nPERFORMANCE ON TEST SET: Batch Loss = 0.7110071778297424, Accuracy = 0.8836104273796082\nTraining iter #1590000:   Batch Loss = 0.534237, Accuracy = 0.8513333201408386\nPERFORMANCE ON TEST SET: Batch Loss = 0.7369688749313354, Accuracy = 0.8313539028167725\nTraining iter #1620000:   Batch Loss = 0.380147, Accuracy = 0.9466666579246521\nPERFORMANCE ON TEST SET: Batch Loss = 0.5730095505714417, Accuracy = 0.8819137811660767\nTraining iter #1650000:   Batch Loss = 0.399804, Accuracy = 0.9200000166893005\nPERFORMANCE ON TEST SET: Batch Loss = 0.5721645355224609, Accuracy = 0.8893790245056152\nTraining iter #1680000:   Batch Loss = 0.407757, Accuracy = 0.9226666688919067\nPERFORMANCE ON TEST SET: Batch Loss = 0.5266643762588501, Accuracy = 0.9005768299102783\nTraining iter #1710000:   Batch Loss = 0.385811, Accuracy = 0.9326666593551636\nPERFORMANCE ON TEST SET: Batch Loss = 0.5688514709472656, Accuracy = 0.8978622555732727\nTraining iter #1740000:   Batch Loss = 0.292420, Accuracy = 0.9773333072662354\nPERFORMANCE ON TEST SET: Batch Loss = 0.5509792566299438, Accuracy = 0.9009161591529846\nTraining iter #1770000:   Batch Loss = 0.283246, Accuracy = 0.9853333234786987\nPERFORMANCE ON TEST SET: Batch Loss = 0.5502074360847473, Accuracy = 0.9029521346092224\nTraining iter #1800000:   Batch Loss = 0.269644, Accuracy = 0.984000027179718\nPERFORMANCE ON TEST SET: Batch Loss = 0.5147572755813599, Accuracy = 0.9097387194633484\nTraining iter #1830000:   Batch Loss = 0.319480, Accuracy = 0.9539999961853027\nPERFORMANCE ON TEST SET: Batch Loss = 0.5242997407913208, Accuracy = 0.9083814024925232\nTraining iter #1860000:   Batch Loss = 0.338079, Accuracy = 0.9413333535194397\nPERFORMANCE ON TEST SET: Batch Loss = 0.5505284667015076, Accuracy = 0.9073634147644043\nTraining iter #1890000:   Batch Loss = 0.366936, Accuracy = 0.9399999976158142\nPERFORMANCE ON TEST SET: Batch Loss = 0.6422610282897949, Accuracy = 0.8717339634895325\nTraining iter #1920000:   Batch Loss = 0.334493, Accuracy = 0.940666675567627\nPERFORMANCE ON TEST SET: Batch Loss = 0.6224310994148254, Accuracy = 0.8696979880332947\nTraining iter #1950000:   Batch Loss = 0.348137, Accuracy = 0.9426666498184204\nPERFORMANCE ON TEST SET: Batch Loss = 0.5998332500457764, Accuracy = 0.8903970122337341\nTraining iter #1980000:   Batch Loss = 0.310502, Accuracy = 0.9486666917800903\nPERFORMANCE ON TEST SET: Batch Loss = 0.5465859770774841, Accuracy = 0.900237500667572\nTraining iter #2010000:   Batch Loss = 0.258777, Accuracy = 0.9800000190734863\nPERFORMANCE ON TEST SET: Batch Loss = 0.5901551842689514, Accuracy = 0.9015948176383972\nTraining iter #2040000:   Batch Loss = 0.349976, Accuracy = 0.9306666851043701\nPERFORMANCE ON TEST SET: Batch Loss = 0.5864955186843872, Accuracy = 0.9022734761238098\nTraining iter #2070000:   Batch Loss = 0.327209, Accuracy = 0.9440000057220459\nPERFORMANCE ON TEST SET: Batch Loss = 0.5827186703681946, Accuracy = 0.9009161591529846\nTraining iter #2100000:   Batch Loss = 0.252979, Accuracy = 0.9900000095367432\nPERFORMANCE ON TEST SET: Batch Loss = 0.5870321989059448, Accuracy = 0.8978622555732727\nTraining iter #2130000:   Batch Loss = 0.254144, Accuracy = 0.9786666631698608\nPERFORMANCE ON TEST SET: Batch Loss = 0.5812761783599854, Accuracy = 0.8978622555732727\nTraining iter #2160000:   Batch Loss = 0.232130, Accuracy = 0.9879999756813049\nPERFORMANCE ON TEST SET: Batch Loss = 0.5734394788742065, Accuracy = 0.9012554883956909\nTraining iter #2190000:   Batch Loss = 0.260921, Accuracy = 0.9739999771118164\nPERFORMANCE ON TEST SET: Batch Loss = 0.566673755645752, Accuracy = 0.8961656093597412\nOptimization Finished!\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;optimizer&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1381210249242204&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     18</span>     <span class=\"ansired\"># Fit training using batch data</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     19</span>     _, loss, acc = sess.run(\n<span class=\"ansigreen\">---&gt; 20</span><span class=\"ansiyellow\">         </span><span class=\"ansiyellow\">[</span>optimizer<span class=\"ansiyellow\">,</span> cost<span class=\"ansiyellow\">,</span> accuracy<span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     21</span>         feed_dict={\n<span class=\"ansigreen\">     22</span>             x<span class=\"ansiyellow\">:</span> batch_xs<span class=\"ansiyellow\">,</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;optimizer&apos; is not defined</div>","workflows":[],"startTime":1521788111337,"submitTime":1521788111328,"finishTime":1521789024565,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"405f5b24-6ce9-4e92-a448-cfe9765ca6a7"},{"version":"CommandV1","origId":3300760951503239,"guid":"fbc131d6-c18b-4167-b77c-3455e061d266","subtype":"command","commandType":"auto","position":14.5,"command":"# Accuracy for test data\n\none_hot_predictions, accuracy, final_loss = sess.run(\n    [pred, accuracy, cost],\n    feed_dict={\n        x: X_test,\n        y: one_hot(y_test)\n    }\n)\n\ntest_losses.append(final_loss)\ntest_accuracies.append(accuracy)\n\nprint(\"FINAL RESULT: \" + \\\n      \"Batch Loss = {}\".format(final_loss) + \\\n      \", Accuracy = {}\".format(accuracy))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">FINAL RESULT: Batch Loss = 0.5770002603530884, Accuracy = 0.8965049386024475\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1521791022439,"submitTime":1521791022429,"finishTime":1521791023649,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5d53a3ec-1b98-44a3-8db1-4387ede4c4b7"}],"dashboards":[],"guid":"1058c23e-50b1-4340-8f69-3a2da74d3b81","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/js/metrics-graphics.js"
 onerror="window.mainJsLoadError = true;"></script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/358a53f93460d41f62b95cfd5ce6436b528c2b229982b8159a580fbbb91ef1fb/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
