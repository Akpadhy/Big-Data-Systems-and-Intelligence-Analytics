{"cells":[{"cell_type":"code","source":["# All Includes\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\nfrom sklearn import metrics\n\nimport os"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Useful Constants\n\n# Those are separate normalised input features for the neural network\nINPUT_SIGNAL_TYPES = [\n    \"body_acc_x_\",\n    \"body_acc_y_\",\n    \"body_acc_z_\",\n    \"body_gyro_x_\",\n    \"body_gyro_y_\",\n    \"body_gyro_z_\",\n    \"total_acc_x_\",\n    \"total_acc_y_\",\n    \"total_acc_z_\"\n]\n\n# Output classes to learn how to classify\nLABELS = [\n    \"WALKING\", \n    \"WALKING_UPSTAIRS\", \n    \"WALKING_DOWNSTAIRS\", \n    \"SITTING\", \n    \"STANDING\", \n    \"LAYING\"\n]"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["DATASET_PATH = \"/FileStore/tables/\"\nTRAIN = \"train/\"\nTEST = \"test/\"\n\n\n# Load \"X\" (the neural network's training and testing inputs)\n\ndef load_X(X_signals_paths):\n    X_signals = []\n    \n    for signal_type_path in X_signals_paths:\n      #with open(signal_type_path, \"r\") as file:\n        file = open(\"/dbfs/\"+signal_type_path, 'r')\n        # Read dataset from disk, dealing with text files' syntax\n        X_signals.append(\n            [np.array(serie, dtype=np.float32) for serie in [\n                row.replace('  ', ' ').strip().split(' ') for row in file\n            ]]\n        )\n        file.close()\n    \n    return np.transpose(np.array(X_signals), (1, 2, 0))\n\nX_train_signals_paths = [\n    DATASET_PATH + signal + \"train.txt\" for signal in INPUT_SIGNAL_TYPES\n]\nX_test_signals_paths = [\n    DATASET_PATH + TEST +  signal + \"test.txt\" for signal in INPUT_SIGNAL_TYPES\n]\n\nX_train = load_X(X_train_signals_paths)\nX_test = load_X(X_test_signals_paths)\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Load \"y\" (the neural network's training and testing outputs)\n\ndef load_y(y_path):\n    file = open(\"/dbfs\"+y_path, 'r')\n    # Read dataset from disk, dealing with text file's syntax\n    y_ = np.array(\n        [elem for elem in [\n            row.replace('  ', ' ').strip().split(' ') for row in file\n        ]], \n        dtype=np.int32\n    )\n    file.close()\n    \n    # Substract 1 to each output class for friendly 0-based indexing \n    return y_ - 1\n\ny_train_path = DATASET_PATH + \"y_train.txt\"\ny_test_path = DATASET_PATH + TEST + \"y_test.txt\"\n\ny_train = load_y(y_train_path)\ny_test = load_y(y_test_path)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Input Data \n\ntraining_data_count = len(X_train)  # 7352 training series (with 50% overlap between each serie)\ntest_data_count = len(X_test)  # 2947 testing series\nn_steps = len(X_train[0])  # 128 timesteps per series\nn_input = len(X_train[0][0])  # 9 input parameters per timestep"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["xtrain_df = pd.DataFrame(X_train.reshape(len(X_train),1152))\nytrain_df = pd.DataFrame(y_train.reshape(len(y_train),1))\nxtest_df = pd.DataFrame(X_test.reshape(len(X_test),1152))\nytest_df = pd.DataFrame(y_test.reshape(len(y_test),1))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["feature561_df = pd.read_csv('/dbfs/FileStore/tables/features.txt',header= None, sep='\\s+')\nsubjectTrain_df = pd.read_csv('/dbfs/FileStore/tables/subject_train.txt',header= None, sep='\\s+')\nactivity_lables = pd.read_csv('/dbfs/FileStore/tables/activity_labels.txt',header= None, sep='\\s+')"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["ytrain_df = ytrain_df.rename(columns = {0:'features'})\nsubjectTrain_df = subjectTrain_df.rename(columns = {0:'users'})\nactivity_lables = activity_lables.rename(columns = {0:'key',1:'value'})"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["train_df=pd.concat([xtrain_df,ytrain_df,subjectTrain_df], axis=1)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["activity_lables"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["train_df = train_df.join(activity_lables.set_index('key'), on='features')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["train_df[\"id\"] = train_df.index+1 "],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["train_df[['users','value','features',\"id\"]]"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["import graphframes\nfrom graphframes import *"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.sql.types import *\n#changed_train_df = train_df.select(\"users\", train_df.users.cast(\"String\").alias(\"s_users\")) \ntrain_df['s_users'] = train_df['users'].astype(str)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["train_df.dtypes\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["localvertices = train_df[[\"id\",\"features\"]]\nv = sqlContext.createDataFrame(localvertices, [\"id\",\"Features\"])"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["display(v)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["localedges = train_df[[\"users\",\"features\",\"id\"]]\ne = sqlContext.createDataFrame(localedges, [\"src\",\"dst\",\"id_users\"])"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["display(e)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["g = GraphFrame(v,e)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(g.inDegrees)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["display(g.outDegrees)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["user_count = g.edges.filter(\"src = '1'\").count()\nprint \"Activities by user 1: \",user_count"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["activity_count = g.edges.filter(\"dst = '1'\").count()\nprint \"Walking count by all users: \", activity_count"],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"HAR_Graph","notebookId":1905355796764971},"nbformat":4,"nbformat_minor":0}
